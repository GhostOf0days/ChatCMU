Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.Researchers from Carnegie Mellon University and Fujitsu have developed a new method to convert 2D images to a 3D structure.The work, led by Laszlo A. Jeni’s CUBE Lab in the School of Computer Science, represents a significant breakthrough in addressing a longstanding challenge in computer vision.Harnessing artificial intelligence, Dynamic Light Field Network (DyLiN), handles non-rigid deformations and topological changes and surpasses the current static light field networks.“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.eduABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)Bachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramAdditional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:









    Warning: You are viewing this site with an outdated/unsupported browser.
    Please update your browser or consider using a different one in order to view this site without issue.
    
    For a list of browsers that this site supports, see our Supported Browsers page.
  













 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation 








CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation

June 14, 2023    Aaron Aupperlee


Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.

Researchers from Carnegie Mellon University and Fujitsu have developed a new method to convert 2D images to a 3D structure.
The work, led by Laszlo A. Jeni’s CUBE Lab in the School of Computer Science, represents a significant breakthrough in addressing a longstanding challenge in computer vision.
Harnessing artificial intelligence, Dynamic Light Field Network (DyLiN), handles non-rigid deformations and topological changes and surpasses the current static light field networks.


“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.


For More Information 
Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu


Brian Staszel2023-06-27T11:08:06-04:00 
Share This Story!
FacebookTwitterEmail 


 
 





 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 
 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation 








CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation

June 14, 2023    Aaron Aupperlee


Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.

Researchers from Carnegie Mellon University and Fujitsu have developed a new method to convert 2D images to a 3D structure.
The work, led by Laszlo A. Jeni’s CUBE Lab in the School of Computer Science, represents a significant breakthrough in addressing a longstanding challenge in computer vision.
Harnessing artificial intelligence, Dynamic Light Field Network (DyLiN), handles non-rigid deformations and topological changes and surpasses the current static light field networks.


“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.


For More Information 
Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu


Brian Staszel2023-06-27T11:08:06-04:00 
Share This Story!
FacebookTwitterEmail 


 









 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 










 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 











Search for:










Search for:







Search for:













Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation 







Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation 





Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation 


Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation Home/News/CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation


CMU Collaborates with Fujitsu Researchers on Breakthrough in Dynamic 3D Structure Representation

June 14, 2023    Aaron Aupperlee


Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.

Researchers from Carnegie Mellon University and Fujitsu have developed a new method to convert 2D images to a 3D structure.
The work, led by Laszlo A. Jeni’s CUBE Lab in the School of Computer Science, represents a significant breakthrough in addressing a longstanding challenge in computer vision.
Harnessing artificial intelligence, Dynamic Light Field Network (DyLiN), handles non-rigid deformations and topological changes and surpasses the current static light field networks.


“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.


For More Information 
Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu


Brian Staszel2023-06-27T11:08:06-04:00 
Share This Story!
FacebookTwitterEmail 



June 14, 2023    Aaron Aupperlee


Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.

Researchers from Carnegie Mellon University and Fujitsu have developed a new method to convert 2D images to a 3D structure.
The work, led by Laszlo A. Jeni’s CUBE Lab in the School of Computer Science, represents a significant breakthrough in addressing a longstanding challenge in computer vision.
Harnessing artificial intelligence, Dynamic Light Field Network (DyLiN), handles non-rigid deformations and topological changes and surpasses the current static light field networks.


“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.


For More Information 
Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu

June 14, 2023    Aaron Aupperlee
Dynamic Light Field Network (DyLiN) accommodates dynamic scene deformations, such as in avatar animation, where facial expressions can be used as controllable input attributes.


“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.

“Working with 2D images to create a 3D structure is a complex process that requires a deep understanding of how to handle deformations and changes. DyLiN is our answer to this problem, and it has already shown significant improvements over existing methods in terms of speed and visual fidelity,” said Jeni, a professor in the Robotics Institute.
DyLiN learns a deformation field from input rays to canonical rays and lifts them into a higher dimensional space to handle discontinuities. The team also introduced CoDyLiN, which enhances DyLiN with controllable attribute inputs. Both models were trained via knowledge distillation from pretrained dynamic radiance fields.
During testing, DyLiN exhibited superior performance on both synthetic and real-world datasets containing various non-rigid deformations. DyLiN matched state-of-the-art methods in terms of visual fidelity while being 25-71 times faster computationally. When tested on attribute-annotated data, CoDyLiN surpassed its teacher model.
“The strides made by DyLiN and CoDyLiN mark an exciting progression towards real-time volumetric rendering and animation,” Jeni said. “This improvement in speed without sacrificing fidelity opens up a world of opportunities in various applications.”
The research, supported by Fujitsu Research America, represents significant advancements in the field of 3D modeling and rendering. The implementation of these methodologies could revolutionize industries that heavily rely on deformable 3D models, such as virtual simulation, augmented reality, gaming, and animation. DyLiN and CoDyLiN can accurately render and analyze changes in human movement within a virtual 3D space based on 2D images. It is able to create a 3D avatar from actual images, enabling the transfer of facial expressions from a real person to their virtual counterpart.
The research was conducted by Jeni, Heng Yu, Joel Julin, Zoltan A. Milacski from CMU’s Robotics Institute, and Koichiro Niinuma from Fujitsu Research of America. The team presented its paper, “DyLiN: Making Light Field Networks Dynamic,” in June at the Conference on Vision and Pattern Recognition. More information is available on the project’s website.For More Information 
Aaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu

Share This Story!
FacebookTwitterEmail FacebookTwitterEmailFacebookTwitterEmail




 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 



 Outreach at RI | Contact Us | Giving | RoboGuide

 

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 Outreach at RI | Contact Us | Giving | RoboGuide
Outreach at RI | Contact Us | Giving | RoboGuide



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn


		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 

		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 
FacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedIn