This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)Bachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramAdditional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:










Statement



Publications



Members



Statement



Publications



Members


    Warning: You are viewing this site with an outdated/unsupported browser.
    Please update your browser or consider using a different one in order to view this site without issue.
    
    For a list of browsers that this site supports, see our Supported Browsers page.
  













 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/MMPUG: Multi-Model Perception Uber Good 

















hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)














Statement




Publications




Members









Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 

Alex Krause2023-05-30T13:55:04-04:00 
Share This Story!
FacebookTwitterEmail 


 
 





 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 
 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/MMPUG: Multi-Model Perception Uber Good 

















hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)














Statement




Publications




Members









Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 

Alex Krause2023-05-30T13:55:04-04:00 
Share This Story!
FacebookTwitterEmail 


 









 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 










 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 











Search for:










Search for:







Search for:













Home/MMPUG: Multi-Model Perception Uber Good 







Home/MMPUG: Multi-Model Perception Uber Good 





Home/MMPUG: Multi-Model Perception Uber Good 


Home/MMPUG: Multi-Model Perception Uber Good Home/MMPUG: Multi-Model Perception Uber Good











hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)














Statement




Publications




Members









Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 

Alex Krause2023-05-30T13:55:04-04:00 
Share This Story!
FacebookTwitterEmail 













hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)














Statement




Publications




Members









Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 

Alex Krause2023-05-30T13:55:04-04:00 
Share This Story!
FacebookTwitterEmail 






hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)








hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)






hero image




					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)




hero image


hero image


					MMPUG: Multi-Model Perception Uber Good				


Lab: Biorobotics Lab and Field Robotics Center (FRC)


					MMPUG: Multi-Model Perception Uber Good				
Lab: Biorobotics Lab and Field Robotics Center (FRC)
Lab: Biorobotics Lab and Field Robotics Center (FRC)




Statement




Publications




Members









Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 

Alex Krause2023-05-30T13:55:04-04:00 
Share This Story!
FacebookTwitterEmail 




Statement




Publications




Members








Statement









This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.






Publications








Displaying 1 Publications









Members








 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






 




Statement





This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.


This project seeks novel approaches to rapidly map, navigate, and search environments for situational awareness during time-sensitive combat operations. This project focuses on fast-moving autonomous vehicles designed for multi-modal exploration across various terrains and environments. To do this, we integrate and iterate upon previously designed algorithms for exploration, finding areas where common algorithms fail when used with high-speed UGVs and creating novel solutions to push the boundaries of what these vehicles are capable of. In addition, our system boasts a heterogeneous robot setup via legged robots that can aid exploration between multiple floors.
Fig: Heterogeneous agent system with three RC cars (UGVs) and two Spots (legged robots)
The current design combines a viewpoint-based exploration planner, trajectory libraries for rapid elimination of paths intersecting with obstacles, and a low-level planner capable of following paths at a high speed. An important aspect of the software architecture is its hierarchical design which allows the operator of the UGV to insert human feedback at any stage of the process. Specifically, this allows the operator to bias the exploration planner, give direct waypoint input, operate in a smart joystick mode (which follows the operator’s input while avoiding obstacles), or directly follow user input. The stack is then able to optimize the exploration process by utilizing different levels of autonomy to flexibly perform what the operator desires.
Fig: The third RC car in the convoy peels off to explore an unknown passage on the right
Our recent efforts involved creating a convoy of wheeled robots that could operate at higher speeds in both indoor and outdoor environments. We extended this capability to heterogeneous agents involving the Spot robots and illustrated that our optimal control algorithms are vehicle agnostic. Further, an explicit peel-off behavior was designed to ensure the trail vehicles could peel off from the convoy and act as radio beacons for the lead vehicles. In some scenarios, peeling off a part of the convoy to explore unknown terrains when there is a fork in the road has proven to be extremely helpful for heterogeneous multi-agent exploration. Once again, the hierarchical design allows the operator to provide feedback mid-exploration, and one of our new features includes bringing in new operators to handle peeled-off robots for a different mission.




Publications




Displaying 1 Publications




Displaying 1 Publications



Members




 
head 






Sebastian Scherer









Matthew J. Travers






 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy






 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh






  
head 






Sebastian Scherer









Matthew J. Travers







head 






Sebastian Scherer









Matthew J. Travers











Sebastian Scherer









Matthew J. Travers









Sebastian Scherer







Sebastian Scherer



Sebastian Scherer





Matthew J. Travers







Matthew J. Travers



Matthew J. Travers
 
staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy







staff Members






Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy











Nathaniel Shoemaker-Trejo









Parvathiswara Bhaskar Vundurthy









Nathaniel Shoemaker-Trejo







Nathaniel Shoemaker-Trejo



Nathaniel Shoemaker-Trejo





Parvathiswara Bhaskar Vundurthy







Parvathiswara Bhaskar Vundurthy



Parvathiswara Bhaskar Vundurthy
 
student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh







student Members






Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh











Namya Bagree(MechE)









Rohan Chandrasekar









Adam Johnson(ECE)









James Maier









Chase Noren









Sourojit Saha(MechE)









Burhanuddin Shirose









Damanpreet Singh(MechE)









Joshua Spisak









Prasanna Kettavarapalyam Sriganesh









Namya Bagree(MechE)







Namya Bagree(MechE)



Namya Bagree(MechE)





Rohan Chandrasekar







Rohan Chandrasekar



Rohan Chandrasekar





Adam Johnson(ECE)







Adam Johnson(ECE)



Adam Johnson(ECE)





James Maier







James Maier



James Maier





Chase Noren







Chase Noren



Chase Noren





Sourojit Saha(MechE)







Sourojit Saha(MechE)



Sourojit Saha(MechE)





Burhanuddin Shirose







Burhanuddin Shirose



Burhanuddin Shirose





Damanpreet Singh(MechE)







Damanpreet Singh(MechE)



Damanpreet Singh(MechE)





Joshua Spisak







Joshua Spisak



Joshua Spisak





Prasanna Kettavarapalyam Sriganesh







Prasanna Kettavarapalyam Sriganesh



Prasanna Kettavarapalyam Sriganesh

Share This Story!
FacebookTwitterEmail FacebookTwitterEmailFacebookTwitterEmail




 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 



 Outreach at RI | Contact Us | Giving | RoboGuide

 

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 Outreach at RI | Contact Us | Giving | RoboGuide
Outreach at RI | Contact Us | Giving | RoboGuide



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn


		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 

		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 
FacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedIn