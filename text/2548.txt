Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC BerkeleyMore Information
Kaitlyn Buss
                RI Seminar Contact

Christine Downey
                VASC Seminar Contact

Abhisesh Silwal
                FRC Seminar Contact

Debra Tobin
                Manager, Media, Events & Website
ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)Bachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramAdditional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








MSR Thesis TallK: Aarrushi ShandilyaMSR Thesis Talk: Anirudha Ramesh
    Warning: You are viewing this site with an outdated/unsupported browser.
    Please update your browser or consider using a different one in order to view this site without issue.
    
    For a list of browsers that this site supports, see our Supported Browsers page.
  













 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos 








Suzanne Lyons Muth

2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh













 Details 

 Date: 

 Thursday, July 20  

 Time: 


					1:00 pm - 3:00 pm									

Event Categories: PhD Thesis Defense, Student Talks



 Venue 

 NSH 4305 



Sync CalendarEvent Contacts


Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website


 

 
 
 





 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 
 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 



















Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos 








Suzanne Lyons Muth

2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh













 Details 

 Date: 

 Thursday, July 20  

 Time: 


					1:00 pm - 3:00 pm									

Event Categories: PhD Thesis Defense, Student Talks



 Venue 

 NSH 4305 



Sync CalendarEvent Contacts


Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website


 

 
 









 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 












 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 










 ABOUTDiversity, Equity and InclusionHiring Faculty PositionsHistory of the Robotics InstituteMaps, Directions & ParkingRI Branding & IdentityPEOPLEAllFacultySpecial FacultyPostdocsStaffInstitute StaffProject StaffStudentsPhDMSRMSCVMRSDAll RI StudentsNon-RI Student EmployeesVisitorsAdjunct Faculty and AffiliatesAlumniRESEARCHResearchPublicationsCentersLabs & GroupsProjectsRobotsEDUCATIONAcademic ProgramsBachelor of Science in Robotics (BSR)Additional Major in RoboticsMinor in RoboticsAccelerated Graduate ProgramMaster of Science in Robotics (MSR)Master of Science in Robotic Systems Development (MRSD)Master of Science in Computer Vision (MSCV)Doctoral in Robotics (PhD)CoursesCMU Student ServicesRI Student LifeRI Summer ScholarsNEWSVideosEVENTSAll EventsSeminarsStudent TalksSpecial EventsFaculty EventsStaff EventsRobotics Institute Seminar VideosNREC


Search for:








 











Search for:










Search for:







Search for:













Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos 







Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos 





Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos 


Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos Home/Student Talks/PhD Thesis Defense/Building 4D Models of Objects and Scenes from Monocular Videos


Suzanne Lyons Muth

2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh













 Details 

 Date: 

 Thursday, July 20  

 Time: 


					1:00 pm - 3:00 pm									

Event Categories: PhD Thesis Defense, Student Talks



 Venue 

 NSH 4305 



Sync CalendarEvent Contacts


Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website


 

 

Suzanne Lyons Muth

2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh









2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh







2023-07-20 13:00:002023-07-20 15:00:00


This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh







This event has passed.×


PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar

 


Share This Event!




Facebook



Twitter

Email










Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh




This event has passed.×This event has passed.

PhD Thesis Defense
July


20
Thu







Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export



+ Google Calendar+ Add to iCalendar


PhD Thesis Defense
July

20
Thu
20Thu




Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information


+ iCal Export





Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University



	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        








Building 4D Models of Objects and Scenes from Monocular Videos


Gengshan Yang
PhD Student
Robotics Institute, Carnegie Mellon University


	                        
	                        	                        
	                        Thursday, July 201:00 pm to 3:00 pm
	                        	                            	                            	                            	                            	                                NSH 4305	                                                        










Building 4D Models of Objects and Scenes from Monocular Videos
Abstract: 
We explore how to infer the time-varying 3D structures of generic, deformable objects, and dynamic scenes from monocular videos. A solution to this problem is essential for virtual reality and robotics applications. However, inferring 4D structures given 2D observations is challenging due to its under-constrained nature. In a casual setup where there is neither complete sensor measurement nor rich 3D supervision, one needs to tackle three challenges — (1) Registration: how to find correspondence of pixels and track the camera frame over time? (2) Scale ambiguity: how to lift 2D observations to 3D? (3) Occlusion: how to infer the structures that are not observable due to self-occlusion or occlusion by the others?
We first study the 4D reconstruction problem in a single video setup and then extend it to multiple videos, different instances, and scenes. Inspired by analysis-by-synthesis, we set up an inverse graphics problem and solve it with generic data-driven priors. Inverse graphics models (e.g., differentiable rendering, differentiable physics simulation) approximate the true generation process of a video with differentiable operations, allowing one to inject prior knowledge about the physical world and compute gradients to update the model parameters. Generic data-driven priors (e.g., optical flow, pixel features, viewpoint) provide guidance to register pixels to a canonical 3D space, which allows us to fuse observations over time and across similar instances. Building upon these observations, we develop methods to capture 4D models of deformable objects and dynamic scenes from in-the-wild video footage. In the end, we show that offline-optimized 4D models can be distilled into efficient neural architectures, enabling real-time reconstruction.
Thesis Committee Members:
Deva Ramanan, Chair
Shubham Tulsiani
Jessica Hodgins
Yaser Sheikh
Angjoo Kanazawa, UC Berkeley
More Information

+ iCal Export
+ Google Calendar+ Add to iCalendar

Share This Event!




Facebook



Twitter

Email







Share This Event!




Facebook



Twitter

Email









Facebook



Twitter

Email







Facebook



Twitter

Email





Event Navigation

MSR Thesis TallK: Aarrushi Shandilya
MSR Thesis Talk: Anirudha Ramesh




 Details 

 Date: 

 Thursday, July 20  

 Time: 


					1:00 pm - 3:00 pm									

Event Categories: PhD Thesis Defense, Student Talks



 Venue 

 NSH 4305 



 Details 

 Date: 

 Thursday, July 20  

 Time: 


					1:00 pm - 3:00 pm									

Event Categories: PhD Thesis Defense, Student Talks


					1:00 pm - 3:00 pm									
 Venue 

 NSH 4305 

Sync CalendarSync CalendarEvent Contacts


Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website


Event Contacts


Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website





Kaitlyn Buss
                RI Seminar Contact




Christine Downey
                VASC Seminar Contact




Abhisesh Silwal
                FRC Seminar Contact




Debra Tobin
                Manager, Media, Events & Website




Kaitlyn Buss
                RI Seminar Contact



Christine Downey
                VASC Seminar Contact



Abhisesh Silwal
                FRC Seminar Contact



Debra Tobin
                Manager, Media, Events & Website

 







 Outreach at RI | Contact Us | Giving | RoboGuide

 

 
 
 





		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 
 
 



 Outreach at RI | Contact Us | Giving | RoboGuide

 

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 


 Outreach at RI | Contact Us | Giving | RoboGuide

 Outreach at RI | Contact Us | Giving | RoboGuide
Outreach at RI | Contact Us | Giving | RoboGuide



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn
 



		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 


FacebookTwitterYouTubeInstagramLinkedIn


		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 

		©  The Robotics Institute is part of the School of Computer Science, Carnegie Mellon University.  Legal Info 
FacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedInFacebookTwitterYouTubeInstagramLinkedIn